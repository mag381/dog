{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Efficient_AD_Segmentation_2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPxGbstGs4+XDytdT4/46eb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mag381/dog/blob/main/Efficient_AD_Segmentation_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "異常検知】学習ゼロの衝撃！を可視化する by @shinmura0\n",
        "https://qiita.com/shinmura0/items/5f2c363812f7cdcc8771\n",
        "Modeling the Distribution of Normal Data in Pre-Trained Deep Features for Anomaly Detection\n",
        "https://arxiv.org/abs/2005.14140"
      ],
      "metadata": {
        "id": "eBDz5rLtLVjk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uFwi_2vFN6zT"
      },
      "outputs": [],
      "source": [
        "####### input condition ############\n",
        "model_name = 'tf_efficientnet_b6_ns'\n",
        "level = 7\n",
        "\n",
        "#target = \"capsule\"\n",
        "#target = \"screw\"\n",
        "#target = \"pill\"\n",
        "#target = \"bottle\"\n",
        "#target = \"grid\"\n",
        "#target = \"zipper\"\n",
        "#target = \"transistor\"\n",
        "#target = \"wood\"\n",
        "#target = \"toothbrush\"\n",
        "#target = \"tile\"\n",
        "#target = \"metal_nut\"\n",
        "#target = \"hazelnut\"\n",
        "target = \"cable\"\n",
        "#target = \"leather\"\n",
        "#target = \"carpet\"\n",
        "\n",
        "RESIZE = 528\n",
        "sample_no = 54\n",
        "####################################"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install timm"
      ],
      "metadata": {
        "id": "lJs6Zq8FN8iS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_color_list = [\"screw\", \"grid\", \"zipper\"]\n",
        "to_color = False\n",
        "\n",
        "if target in to_color_list:\n",
        "    to_color = True\n",
        "print(\"to_color is \",to_color)\n",
        "\n",
        "device=\"cuda\""
      ],
      "metadata": {
        "id": "-5f8v_IOODVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import glob\n",
        "import sys, os, urllib.request, tarfile, cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.utils.data as data\n",
        "from typing import Optional, List\n",
        "from torchvision import models, transforms\n",
        "import random\n",
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)  # type: ignore\n",
        "    torch.backends.cudnn.deterministic = True  # type: ignore\n",
        "    torch.backends.cudnn.benchmark = True  # type: ignore\n",
        "def MVTechAD(download_dir, path):\n",
        "    target_path = \"data/\"\n",
        "\n",
        "    if not os.path.exists(download_dir):\n",
        "        os.mkdir(download_dir)\n",
        "\n",
        "    # download file\n",
        "    def _progress(count, block_size, total_size):\n",
        "        sys.stdout.write('\\rDownloading %s %.2f%%' % (source_path,\n",
        "            float(count * block_size) / float(total_size) * 100.0))\n",
        "        sys.stdout.flush()\n",
        "\n",
        "    source_path = path\n",
        "    dest_path = os.path.join(download_dir, \"data.tar.xz\")\n",
        "    urllib.request.urlretrieve(source_path, filename=dest_path, reporthook=_progress)\n",
        "    # untar\n",
        "    with tarfile.open(dest_path, \"r:xz\") as tar:\n",
        "        tar.extractall(target_path)\n",
        "class ImageTransform():\n",
        "    def __init__(self, resize=RESIZE):\n",
        "        self.data_transform = {\n",
        "            'train': transforms.Compose([\n",
        "                transforms.Resize(resize),  # リサイズ\n",
        "                #transforms.RandomCrop(224),\n",
        "                #transforms.RandomRotation(20, fill=200),\n",
        "                #transforms.RandomHorizontalFlip(),  # データオーギュメンテーション\n",
        "                transforms.ToTensor(),  # テンソルに変換\n",
        "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))  # 0-1 → 標準化\n",
        "            ]),\n",
        "            'val': transforms.Compose([\n",
        "                transforms.Resize(resize),  # リサイズ\n",
        "                #transforms.CenterCrop(224),  # 画像中央をresize×resizeで切り取り\n",
        "                transforms.ToTensor(),  # テンソルに変換\n",
        "                transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))  # 0-1 → 標準化\n",
        "            ])\n",
        "        }\n",
        "\n",
        "    def __call__(self, img, phase='train'):\n",
        "        return self.data_transform[phase](img)\n",
        "def fig_show(img):\n",
        "    # 2. 元の画像の表示\n",
        "    plt.imshow(img)\n",
        "    plt.title(\"Original\")\n",
        "    plt.show()\n",
        "\n",
        "    transform = ImageTransform()\n",
        "    img_transformed = transform(img, phase=\"train\")  # torch.Size([3, 224, 224])\n",
        "\n",
        "    # (色、高さ、幅)を (高さ、幅、色)に変換し、0-1に値を制限して表示\n",
        "    plt.subplot(1,2,1)\n",
        "    img_transformed = img_transformed.numpy().transpose((1, 2, 0))\n",
        "    img_transformed = np.clip(img_transformed, 0, 1)\n",
        "    plt.imshow(img_transformed*255)\n",
        "    plt.title(\"Train\")\n",
        "    plt.show()\n",
        "\n",
        "set_seed(1213)"
      ],
      "metadata": {
        "id": "S_tJMYofOGTw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isdir(\"data/\" + target):\n",
        "    MVTechAD(\"./ad\", \"https://www.mydrive.ch/shares/38536/3830184030e49fe74747669442f0f282/download/420937413-1629951498/\" + target + \".tar.xz\")\n",
        "\n",
        "image_file_path = 'data/' + target + '/train/good/000.png'\n",
        "img = Image.open(image_file_path).convert(\"RGB\")   # [高さ][幅][色RGB]\n",
        "\n",
        "fig_show(img)   "
      ],
      "metadata": {
        "id": "VWzI92bJPRrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_list = glob.glob(\"data/\" + target + \"/train/**/**.png\")\n",
        "test_list = glob.glob(\"data/\" + target + \"/test/**/**.png\")\n",
        "\n",
        "normal_list, anomaly_list = [], []\n",
        "\n",
        "for i in range(len(test_list)):\n",
        "    if \"good\" in test_list[i]:\n",
        "        normal_list.append(test_list[i])\n",
        "    else:\n",
        "        anomaly_list.append(test_list[i])\n",
        "\n",
        "print(len(train_list))\n",
        "print(len(normal_list))\n",
        "print(len(anomaly_list))"
      ],
      "metadata": {
        "id": "3v87iyOpPekh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(data.Dataset):\n",
        "    def __init__(self, \n",
        "                 train_list: List[List[str]], \n",
        "                 to_color=\"False\"):\n",
        "        self.file_list = train_list\n",
        "        self.to_color = to_color\n",
        "        self.transform = ImageTransform()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        img_path = self.file_list[idx]\n",
        "        if self.to_color:\n",
        "            img = Image.open(img_path).convert(\"RGB\")  # [高さ][幅][色RGB]\n",
        "        else:\n",
        "            img = Image.open(img_path)\n",
        "\n",
        "        # 画像の前処理を実施\n",
        "        img = self.transform(img, \"train\")\n",
        "\n",
        "        return img\n",
        "\n",
        "# 実行\n",
        "train_dataset = Dataset(train_list, to_color=to_color)\n",
        "normal_dataset = Dataset(normal_list, to_color=to_color)\n",
        "anomaly_dataset = Dataset(anomaly_list, to_color=to_color)\n",
        "\n",
        "# 動作確認\n",
        "index = 25\n",
        "output = anomaly_dataset.__getitem__(index)\n",
        "print(output.size())"
      ],
      "metadata": {
        "id": "NwDCMF4F8sEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make model"
      ],
      "metadata": {
        "id": "K5eluLdZ8vxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "from timm.models.efficientnet import EfficientNet\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def extract_features(inputs: torch.Tensor, \n",
        "                     model: EfficientNet,\n",
        "                     level):\n",
        "    features = dict()\n",
        "    # extract stem features as level 1\n",
        "    x = model.conv_stem(inputs)\n",
        "    x = model.bn1(x)\n",
        "    x = model.act1(x)\n",
        "    features['level_1'] = F.adaptive_avg_pool2d(x, 1)\n",
        "    # extract blocks features as level 2~8\n",
        "    for i, block_layer in enumerate(model.blocks):\n",
        "        x = block_layer(x)\n",
        "        features[f'level_{i+2}'] = F.adaptive_avg_pool2d(x, 1)\n",
        "    # extract top features as level\n",
        "    x = model.conv_head(x)\n",
        "    x = model.bn2(x)\n",
        "    x = model.act2(x)\n",
        "    features['level_9'] = F.adaptive_avg_pool2d(x, 1)\n",
        "    return features['level_{}'.format(str(level))]\n",
        "\n",
        "model = timm.create_model(model_name, pretrained=True)\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "F_4B4qWQ8wft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract feature"
      ],
      "metadata": {
        "id": "YLwcWvXY87-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sklearn.covariance import LedoitWolf\n",
        "\n",
        "def get_mean_cov(loader):\n",
        "    feat = []\n",
        "\n",
        "    for inputs in loader:\n",
        "        inputs = inputs.to(device)\n",
        "        feat_list = extract_features(inputs, model, level) # levelは1~9のint, featuresは上述のextract_features()結果\n",
        "        feat_list = feat_list.cpu().detach().numpy()\n",
        "        #print(feat_list.shape)\n",
        "        for i in range(len(feat_list)):\n",
        "            feat.append(feat_list[i].reshape(-1))\n",
        "\n",
        "    feat = np.array(feat)\n",
        "    #print(feat.shape)\n",
        "\n",
        "    mean = np.mean(feat, axis=0)\n",
        "    cov = np.cov(feat.T)\n",
        "\n",
        "    return feat, mean, cov\n",
        "\n",
        "train_loader = data.DataLoader(train_dataset, \n",
        "                               batch_size=1, \n",
        "                               shuffle=False, \n",
        "                               num_workers=2, \n",
        "                               pin_memory=True, \n",
        "                               drop_last=True)\n",
        "\n",
        "normal_loader = data.DataLoader(normal_dataset, \n",
        "                                batch_size=1, \n",
        "                                shuffle=False, \n",
        "                                num_workers=2, \n",
        "                                pin_memory=True, \n",
        "                                drop_last=True)\n",
        "\n",
        "anomaly_loader = data.DataLoader(anomaly_dataset, \n",
        "                                batch_size=1, \n",
        "                                shuffle=False, \n",
        "                                num_workers=2, \n",
        "                                pin_memory=True, \n",
        "                                drop_last=True)\n",
        "\n",
        "train_feat, mean, cov = get_mean_cov(train_loader)\n",
        "normal_feat, _, _ = get_mean_cov(normal_loader)\n",
        "anomaly_feat, _, _ = get_mean_cov(anomaly_loader)\n",
        "\n",
        "print(mean.shape, cov.shape)"
      ],
      "metadata": {
        "id": "7aSsd9HV88d9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.spatial import distance\n",
        "\n",
        "def get_score(feat, mean, cov):\n",
        "    result = []\n",
        "    # 分散共分散行列の逆行列を計算\n",
        "    cov_i = np.linalg.pinv(cov)\n",
        "\n",
        "    for i in range(len(feat)):\n",
        "        result.append(distance.mahalanobis(feat[i], mean, cov_i))\n",
        "    return result, cov_i\n",
        "\n",
        "normal_score, cov_i = get_score(normal_feat, mean, cov)\n",
        "anomaly_score, _ = get_score(anomaly_feat, mean, cov)"
      ],
      "metadata": {
        "id": "zcC4z-UB9KOz"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detection AUC"
      ],
      "metadata": {
        "id": "TYO474iC9ZTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "\n",
        "def get_auc(Z1, Z2):\n",
        "    plt.title(\"Mahalanobis distance\")\n",
        "    plt.plot(Z1, label=\"normal\")\n",
        "    plt.plot(Z2, label=\"anomaly\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    y_true = np.zeros(len(Z1)+len(Z2))\n",
        "    y_true[len(Z1):] = 1#0:正常、1：異常\n",
        "\n",
        "    # FPR, TPR(, しきい値) を算出\n",
        "    fpr, tpr, _ = metrics.roc_curve(y_true, np.hstack((Z1, Z2)))\n",
        "\n",
        "    # AUC\n",
        "    auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "    return fpr, tpr, auc\n",
        "\n",
        "def plot_roc(Z1, Z2, name):\n",
        "    fpr, tpr, auc1 = get_auc(Z1, Z2)\n",
        "    plt.plot(fpr, tpr, label=name + '(AUC = %.3f)'%(auc1))\n",
        "\n",
        "    plt.legend()\n",
        "    plt.title(name + '(ROC)')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    return auc1\n",
        "\n",
        "_ = plot_roc(normal_score, anomaly_score, target)"
      ],
      "metadata": {
        "id": "37d6a3sG9QnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualization"
      ],
      "metadata": {
        "id": "yMy9fHgl9mWr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_score_pytorch(feature, mean, cov_i):\n",
        "    mean = torch.from_numpy(mean).to(device).float()\n",
        "    cov_i = torch.from_numpy(cov_i).to(device).float()\n",
        "    result = torch.matmul(feature - mean, cov_i)\n",
        "    result = torch.matmul(result, feature - mean)\n",
        "    print(\"Mahalanobis distance\", torch.sqrt(result))\n",
        "    return torch.sqrt(result)\n",
        "\n",
        "def make_fig(fig):\n",
        "    img_mean = [0.485, 0.456, 0.406]\n",
        "    img_std = [0.229, 0.224, 0.225]\n",
        "    img = fig.clone().cpu().detach().numpy()\n",
        "    img = img[0].transpose(1,2,0)\n",
        "    for i in range(3):\n",
        "        img[:,:,i] = img[:,:,i]*img_std[i]+img_mean[i]\n",
        "    return img"
      ],
      "metadata": {
        "id": "kyszjwqk9m-o"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ハイパラ\n",
        "alpha = 0.0001\n",
        "lamda = 1\n",
        "\n",
        "figures=[]\n",
        "\n",
        "# get figure\n",
        "no = 0\n",
        "for x_0 in anomaly_loader:\n",
        "    if no==sample_no:\n",
        "        break\n",
        "    no+=1\n",
        "\n",
        "figures.append(make_fig(x_0))\n",
        "\n",
        "# initial backward\n",
        "x_0 = x_0.to(device).clone().detach().requires_grad_(True)\n",
        "feature = extract_features(x_0.to(device), model, level) # levelは1~9のint, featuresは上述のextract_features()結果\n",
        "loss = get_score_pytorch(feature.view(-1), mean, cov_i)\n",
        "loss.backward(retain_graph=True)\n",
        "\n",
        "x_grad = x_0.grad.data\n",
        "x_t = x_0 - alpha * x_grad\n",
        "\n",
        "# backward iteration\n",
        "for i in range(50):\n",
        "    feature = extract_features(x_t.to(device), model, level) # levelは1~9のint, featuresは上述のextract_features()結果\n",
        "    score = get_score_pytorch(feature.view(-1), mean, cov_i)\n",
        "    loss = score + lamda * torch.abs(x_t - x_0).sum()\n",
        "    loss.backward(retain_graph=True)\n",
        "\n",
        "    x_grad = x_0.grad.data\n",
        "    x_t = x_t - alpha * x_grad\n",
        "    figures.append(make_fig(x_t))"
      ],
      "metadata": {
        "id": "6b8OD1hW9qbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Result"
      ],
      "metadata": {
        "id": "WDaot5gp9xvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "diff = np.abs(figures[0]-figures[-1])\n",
        "diff = np.sum(diff, axis=-1)\n",
        "diff = (diff-np.min(diff))/(np.max(diff)-np.min(diff))\n",
        "\n",
        "#plt.imshow(diff, cmap=\"jet\")#figures[0]-figures[-1])\n",
        "jetcam = cv2.applyColorMap(np.uint8(255 * diff), cv2.COLORMAP_JET)  # モノクロ画像に疑似的に色をつける\n",
        "jetcam = cv2.cvtColor(jetcam, cv2.COLOR_BGR2RGB)  # 色をRGBに変換\n",
        "jetcam = (np.float32(jetcam) + figures[0] / 2)   # もとの画像に合成\n",
        "\n",
        "plt.figure(figsize=(10,10))\n",
        "plt.subplot(1,2,1)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(figures[0])\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(jetcam)\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OdzUXeZy9zLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "References\n",
        "https://qiita.com/kogepan102/items/122b2862ad5a51180656\n",
        "https://qiita.com/sUeharaE4/items/023455822376c07cd6ef\n",
        "https://www.mvtec.com/company/research/datasets/mvtec-ad"
      ],
      "metadata": {
        "id": "nZVMLN9G942Y"
      }
    }
  ]
}