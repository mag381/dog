{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test04.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyORaEhTgFEbMbkhM1L0XEC3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mag381/dog/blob/main/test04.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test04.jpynb"
      ],
      "metadata": {
        "id": "3e1xl5hBhqN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "wMY-uKyZOdw5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMMWZjJ8G5O-"
      },
      "outputs": [],
      "source": [
        "!pip install keras==2.2.5\n",
        "!pip install tensorflow==1.14.0\n",
        "!pip install h5py==2.10.0\n",
        "\n",
        "!pip install icrawler\n",
        "from icrawler.builtin import BingImageCrawler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  猫、犬の画像取得始まり\n",
        "\n",
        "# 猫の画像を100枚取得\n",
        "crawler = BingImageCrawler(storage={\"root_dir\": \"cat\"})\n",
        "crawler.crawl(keyword=\"猫\", max_num=50)\n",
        "\n",
        "from icrawler.builtin import BingImageCrawler\n",
        "\n",
        "# 犬の画像を100枚取得\n",
        "crawler = BingImageCrawler(storage={\"root_dir\": \"dog\"})\n",
        "crawler.crawl(keyword=\"犬\", max_num=50)\n",
        "\n",
        "#  猫、犬の画像取得終わり"
      ],
      "metadata": {
        "id": "kljZCcAjG84m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  画像データ分割の始まり\n",
        "\n",
        "from PIL import Image\n",
        "import os, glob\n",
        "import numpy as np\n",
        "from PIL import ImageFile\n",
        "# IOError: image file is truncated (0 bytes not processed)回避のため\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "classes = [\"dog\", \"cat\"]\n",
        "num_classes = len(classes)\n",
        "image_size = 64\n",
        "num_testdata = 25\n",
        "\n",
        "X_train = []\n",
        "X_test  = []\n",
        "y_train = []\n",
        "y_test  = []\n",
        "\n",
        "for index, classlabel in enumerate(classes):\n",
        "    photos_dir = \"./\" + classlabel\n",
        "    files = glob.glob(photos_dir + \"/*.jpg\")\n",
        "    for i, file in enumerate(files):\n",
        "        image = Image.open(file)\n",
        "        image = image.convert(\"RGB\")\n",
        "        image = image.resize((image_size, image_size))\n",
        "        data = np.asarray(image)\n",
        "        if i < num_testdata:\n",
        "            X_test.append(data)\n",
        "            y_test.append(index)\n",
        "        else:\n",
        "\n",
        "            # angleに代入される値\n",
        "            # -20\n",
        "            # -15\n",
        "            # -10\n",
        "            #  -5\n",
        "            # 0\n",
        "            # 5\n",
        "            # 10\n",
        "            # 15\n",
        "            for angle in range(-20, 20, 5):\n",
        "\n",
        "                img_r = image.rotate(angle)\n",
        "                data = np.asarray(img_r)\n",
        "                X_train.append(data)\n",
        "                y_train.append(index)\n",
        "                # FLIP_LEFT_RIGHT　は 左右反転\n",
        "                img_trains = img_r.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "                data = np.asarray(img_trains)\n",
        "                X_train.append(data)\n",
        "                y_train.append(index)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "X_test  = np.array(X_test)\n",
        "y_train = np.array(y_train)\n",
        "y_test  = np.array(y_test)\n",
        "\n",
        "xy = (X_train, X_test, y_train, y_test)\n",
        "np.save(\"./dog_cat.npy\", xy)\n",
        "\n",
        "#  画像データ分割の終わり"
      ],
      "metadata": {
        "id": "awbGaXTsHBWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  モデル学習始まり\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras.utils import np_utils\n",
        "import keras\n",
        "import numpy as np\n",
        "\n",
        "classes = [\"dog\", \"cat\"]\n",
        "num_classes = len(classes)\n",
        "image_size = 64\n",
        "\n",
        "\"\"\"\n",
        "データを読み込む関数\n",
        "\"\"\"\n",
        "def load_data():\n",
        "    X_train, X_test, y_train, y_test = np.load(\"./dog_cat.npy\", allow_pickle=True)\n",
        "    # 入力データの各画素値を0-1の範囲で正規化(学習コストを下げるため)\n",
        "    X_train = X_train.astype(\"float\") / 255\n",
        "    X_test  = X_test.astype(\"float\") / 255\n",
        "    # to_categorical()にてラベルをone hot vector化\n",
        "    y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "    y_test  = np_utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test\n",
        "\n",
        "\"\"\"\n",
        "モデルを学習する関数\n",
        "\"\"\"\n",
        "def train(X, y, X_test, y_test):\n",
        "    model = Sequential()\n",
        "\n",
        "    # Xは(1200, 64, 64, 3)\n",
        "    # X.shape[1:]とすることで、(64, 64, 3)となり、入力にすることが可能です。\n",
        "    model.add(Conv2D(32,(3,3), padding='same',input_shape=X.shape[1:]))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(32,(3,3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.1))\n",
        "\n",
        "    model.add(Conv2D(64,(3,3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(64,(3,3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "    model.add(Dropout(0.25))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.45))\n",
        "    model.add(Dense(2))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    # https://keras.io/ja/optimizers/\n",
        "    # 今回は、最適化アルゴリズムにRMSpropを利用\n",
        "    opt = keras.optimizers.rmsprop(lr=0.00005, decay=1e-6)\n",
        "    # https://keras.io/ja/models/sequential/\n",
        "    model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
        "    model.fit(X, y, batch_size=28, epochs=40)\n",
        "    # HDF5ファイルにKerasのモデルを保存\n",
        "    model.save('./cnn.h5')\n",
        "\n",
        "    return model\n",
        "\n",
        "\"\"\"\n",
        "メイン関数\n",
        "データの読み込みとモデルの学習を行います。\n",
        "\"\"\"\n",
        "def main():\n",
        "    # データの読み込み\n",
        "    X_train, y_train, X_test, y_test = load_data()\n",
        "\n",
        "    # モデルの学習\n",
        "    model = train(X_train, y_train, X_test, y_test)\n",
        "\n",
        "main()\n",
        "\n",
        "#  モデル学習終わり"
      ],
      "metadata": {
        "id": "dXEED0hNHGeu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dog1.jpgをColabにアップロードしている前提\n"
      ],
      "metadata": {
        "id": "1dIt1yxlHOXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  推論フェーズ準備始まり\n",
        "\n",
        "import keras\n",
        "import sys, os\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "\n",
        "imsize = (64, 64)\n",
        "\n",
        "#  推論フェーズ準備終わり"
      ],
      "metadata": {
        "id": "tpNPot3ZHQAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  推論フェーズ始まり\n",
        "\n",
        "from google.colab import files\n",
        "uploaded_file = files.upload()\n",
        "uploaded_file_name = next(iter(uploaded_file))\n",
        "img = cv2.imread(uploaded_file_name)\n",
        "show_img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(show_img)\n",
        "testpic     = uploaded_file_name\n",
        "keras_param = \"./cnn.h5\"\n",
        "\n",
        "def load_image(path):\n",
        "    img = Image.open(path)\n",
        "    img = img.convert('RGB')\n",
        "    # 学習時に、(64, 64, 3)で学習したので、画像の縦・横は今回 変数imsizeの(64, 64)にリサイズします。\n",
        "    img = img.resize(imsize)\n",
        "    # 画像データをnumpy配列の形式に変更\n",
        "    img = np.asarray(img)\n",
        "    img = img / 255.0\n",
        "    return img\n",
        "\n",
        "model = load_model(keras_param)\n",
        "img = load_image(testpic)\n",
        "prd = model.predict(np.array([img]))\n",
        "print(prd) # 精度の表示\n",
        "prelabel = np.argmax(prd, axis=1)\n",
        "if prelabel == 0:\n",
        "    print(\">>> 犬\")\n",
        "elif prelabel == 1:\n",
        "    print(\">>> 猫\")\n",
        "\n",
        "#  推論フェーズ終わり"
      ],
      "metadata": {
        "id": "uxMVI_6IHiZ9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}